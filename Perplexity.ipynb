{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ddfdc9-d6a6-46f4-af7d-2ce3f1aa8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f659385f-0c6b-443d-afb6-bbc1bddce019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33afd47c-db67-48ea-b559-ac16e6393a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1592d3f8-7fae-4870-981e-46452b97f09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BertForMaskedLM'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
    "# not sure this works\n",
    "config.architectures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd6d6f46-41d8-4f5c-beb1-8d5a697d9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration plain_text\n"
     ]
    }
   ],
   "source": [
    "data= load_dataset(\"poem_sentiment\",\"plain_text\", split= \"test\", streaming= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8387de14-f987-4de6-855b-54ee85eeb202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['verse_text']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"oscar\", \"unshuffled_deduplicated_en\", \"train\", True,5],\n",
    "        [\"imdb\",\"plain_text\", \"test\", False ,5],\n",
    "        [\"glue\",\"ax\", \"test\", True , 5],\n",
    "        [\"poem_sentiment\",\"plain_text\", \"test\", True ,5],\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "271a8bf4-0d5c-4492-9659-7b51b129da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mods= [\"t5-small\"]\n",
    "\n",
    "datas= [\n",
    "        \n",
    "        [\"c4\", \"en\", \"train\", True, 5]\n",
    "        \n",
    "       ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636f9b6-e6a9-49e6-826c-ddb567b65787",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex_model_data(m_name =\"bert-base-uncased\", d_name =\"oscar\", d_option=\"unshuffled_deduplicated_en\", d_split = \"train\", d_streaming = True, d_size=5 )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "713ae324-1b1d-47e1-a1c6-1dce1b0fdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplex_model_data(**kwargs):\n",
    "    modlist=[]\n",
    "    maskedLM= [\"bert-base-uncased\"]\n",
    "    maskedHead= [\"t5-small\"]\n",
    "    tok = AutoTokenizer.from_pretrained(kwargs['m_name'])\n",
    "    if kwargs['m_name'] in modlist: \n",
    "        pass\n",
    "    elif kwargs['m_name'] in maskedHead:\n",
    "        model = AutoModelWithLMHead.from_pretrained(kwargs['m_name'])\n",
    "    else: \n",
    "        model = AutoModelForMaskedLM.from_pretrained(kwargs['m_name'])\n",
    "        print(str(kwargs['m_name']) + \" model loaded!\")\n",
    "        modlist.append(kwargs['m_name'])\n",
    "    data= load_dataset(kwargs['d_name'], kwargs['d_option'], split= kwargs['d_split'], streaming = kwargs['d_streaming'])\n",
    "    print(str(kwargs['d_name']) + \" dataset loaded!\")\n",
    "    if kwargs['d_streaming'] == True: \n",
    "        data_head = data.take(kwargs['d_size'])\n",
    "        try: \n",
    "            text= [l['text'] for l in list(data_head)]\n",
    "        except:\n",
    "            feature = [d for d in data.features if 'text' in d]\n",
    "            feature=feature[0]\n",
    "            text= [l[feature] for l in list(data_head)]\n",
    "        \n",
    "    else:\n",
    "        feature = next(iter(data.features))\n",
    "        text= data[feature][:kwargs['d_size']]\n",
    "    \n",
    "    encodings = tok('\\n\\n'.join(text), return_tensors='pt')\n",
    "    try:\n",
    "        max_length = model.config.max_position_embeddings\n",
    "    except AttributeError as error:\n",
    "        max_length = model.config.n_positions\n",
    "    except:\n",
    "        max_length=512\n",
    "        \n",
    "    #From https://huggingface.co/transformers/perplexity.html\n",
    "    stride = 512\n",
    "    lls = []\n",
    "    for i in range(0, encodings.input_ids.size(1), stride):\n",
    "        begin_loc = max(i + stride - max_length, 0)\n",
    "        end_loc = min(i + stride, encodings.input_ids.size(1))\n",
    "        trg_len = end_loc - i    # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:,begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:,:-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            log_likelihood = outputs[0] * trg_len\n",
    "\n",
    "        lls.append(log_likelihood)\n",
    "\n",
    "    ppl = torch.exp(torch.stack(lls).sum() / end_loc)\n",
    "    print(\"The perplexity of the \" + str(kwargs['m_name']) + \" model with the \" + str(kwargs['d_name']) + \" dataset is \" + str(ppl.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88ff559e-6ac8-48ad-befa-b451e69a3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combo_pp(models, datasets):\n",
    "    combos= list(itertools.product(models, datasets))\n",
    "    print(\"There are \" + str(len(list(combos))) + \" combinations of models and datasets.\")\n",
    "    for m, d in combos:\n",
    "        print('Analyzing the ' + m + ' model and the ' + d[0] + ' dataset.')\n",
    "        perplex_model_data(m_name= m, d_name= d[0], d_option= d[1], d_split= d[2], d_streaming= d[3], d_size= d[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf508891-2d61-4ab6-8d56-ffc270996855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 combinations of models and datasets.\n",
      "Analyzing the t5-small model and the c4 dataset.\n"
     ]
    }
   ],
   "source": [
    "get_combo_pp(mods,datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47822e1-c233-4560-b7db-a915efd46a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "base_url = \"https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20200501.en/1.0.0/\"\n",
    "data_files = {\"train\": base_url + \"wikipedia-train.parquet\"}\n",
    "wiki = load_dataset(\"parquet\", data_files=data_files, split=\"train\", streaming=True)\n",
    "print(next(iter(wiki)))\n",
    "# {'title': 'Yangliuqing', 'text': 'Yangliuqing () is a market town in Xiqing District...'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f57922-e637-4aa8-8076-3b85d017a210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a002a9a-ac0f-4ab0-94ea-42b86b85ca59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2b0df-1465-499f-b3ca-14aa4e52dad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11c593-faca-4710-bd5c-6b41530bf2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datametrics",
   "language": "python",
   "name": "datametrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
