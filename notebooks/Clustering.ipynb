{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50f8d73-e9db-4d01-abfc-6e71a18786d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b99b0d8-f5e3-48ef-9b8a-97cf9cd50c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c574a62-5c06-41d3-9326-c37f5dcf403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.append('br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c98e42a-5ba8-4dae-9f0b-6a66c1dd35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9ad218-c390-4af8-a780-d09843d21cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b1268e-8454-4e98-96c2-26452ed277e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eca59c2-3959-4629-97ed-a3ff4e62f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/sasha/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"imdb\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b363c4b-99f1-4358-93f6-5e38e8c90a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12fa0c9-1e2e-4f73-9b63-34eff533c432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
       "1  Homelessness (or Houselessness as George Carli...      1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
       "3  This is easily the most underrated film inn th...      1\n",
       "4  This is not the typical Mel Brooks film. It wa...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf7e18d-a121-4d73-9aef-27d18738717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents=datadf.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595915fc-bd52-4102-9fd6-a1fa71ca91cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5d480c6-417c-447b-9eb5-d3f841d1308b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68937a56-8f09-4aa2-81e8-b3a54f59bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = 'word', preprocessor=None, lowercase=True, tokenizer=None, stop_words=stop_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09080a4e-b63d-4f12-bedb-7ff6d5c90695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(sents)\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cc19d-b2fa-4e33-9452-14dedfa8a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup kmeans clustering\n",
    "kmeans = KMeans(n_clusters = 5, n_init = 17,  tol = 0.01, max_iter = 200)\n",
    "#fit the data \n",
    "kmeans.fit(X)\n",
    "#this loop transforms the numbers back into words\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fdca4-6680-4d9d-b653-6fa47beab6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.scikit-yb.org/en/latest/api/cluster/elbow.html\n",
    "\n",
    "visualizer = KElbowVisualizer(kmeans, k=(4,12))\n",
    "\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407091f7-21fd-4187-a50b-0a0f1a26e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup kmeans clustering\n",
    "kmeans = KMeans(n_clusters = 6, n_init = 17,  tol = 0.01, max_iter = 200)\n",
    "#fit the data \n",
    "kmeans.fit(X)\n",
    "#this loop transforms the numbers back into words\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe88351-d38e-43e8-ba45-485f795f3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://stackoverflow.com/questions/57902851/what-vectorizer-should-i-use-when-im-doing-clustering-of-text-data\n",
    "# reduce the features to 2D\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "reduced_features = pca.fit_transform(X.toarray())\n",
    "\n",
    "# reduce the cluster centers to 2D\n",
    "reduced_cluster_centers = pca.transform(kmeans.cluster_centers_)\n",
    "\n",
    "plt.scatter(reduced_features[:,0], reduced_features[:,1], c=kmeans.predict(X), s=3)\n",
    "plt.scatter(reduced_cluster_centers[:, 0], reduced_cluster_centers[:,1], marker='x', s=50, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e6157-7539-4c35-ac86-9f6bbc385bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF vectorizer\n",
    "tfv = TfidfVectorizer(stop_words = stop_words, ngram_range = (1,1))\n",
    "#transform\n",
    "vec_text = tfv.fit_transform(clean_desc)\n",
    "#returns a list of words.\n",
    "words = tfv.get_feature_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datametrics",
   "language": "python",
   "name": "datametrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
