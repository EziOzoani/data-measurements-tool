{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97024cf4-c930-4aa1-a13f-ecdcc2462afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5404d6b6-6ce1-48df-8999-7da3fb082662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be defined by the drop down in the UI\n",
    "subgroup1 = \"woman\"\n",
    "subgroup2 = \"man\"\n",
    "subgroup3 = \"non-binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bf08cc-e18f-49fc-bae7-f03a9a492baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"c4\", \"en\", split= \"train\", streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca6ee78-6f96-45e2-8dad-ec745c953d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Just taking the first 10000 instances.\n"
     ]
    }
   ],
   "source": [
    "grab_n = 10000\n",
    "# For streaming data\n",
    "print('Note: Just taking the first %s instances.' % grab_n)\n",
    "data_head = data.take(grab_n)\n",
    "#data_head = [[\"there is a woman with a hairbrush\"],[\"there is a woman with a hairbrush\"],[\"there is a woman with a hairbrush\"],[\"there is a man with a dog\"],[\"there is a man with a dog\"]]\n",
    "df = pd.DataFrame(data_head, columns=[\"text\"])\n",
    "# If not streaming, use:\n",
    "#df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d4d0c8-fc7c-4e99-8207-2e93d1c9b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vocab_frequencies(df):\n",
    "    \"\"\"\n",
    "    Based on an input pandas DataFrame with a 'text' column, \n",
    "    this function will count the occurrences of all words\n",
    "    with a frequency higher than 'cutoff' and will return another DataFrame\n",
    "    with the rows corresponding to the different vocabulary words\n",
    "    and the column to the count count of that word.\n",
    "    \"\"\"\n",
    "    # Move this up as a constant in larger code.\n",
    "    batch_size = 10\n",
    "    \n",
    "    # We do this to calculate per-word statistics\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    # Regex for pulling out single words\n",
    "    cvec = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\", lowercase=True)\n",
    "    \n",
    "    # We also do this because we need to have the tokenization per sentence \n",
    "    # so that we can look at co-occurrences of words across sentences for nPMI calculation\n",
    "    sent_tokenizer = cvec.build_tokenizer()\n",
    "    df['tokenized'] = df.text.apply(sent_tokenizer)\n",
    "    \n",
    "    # Fast calculation of single word counts\n",
    "    cvec.fit(df.text)\n",
    "    document_matrix = cvec.transform(df.text)\n",
    "    batches = np.linspace(0, df.shape[0], batch_size).astype(int)\n",
    "    i = 0\n",
    "    tf = []\n",
    "    while i < len(batches) - 1:\n",
    "        batch_result = np.sum(document_matrix[batches[i]:batches[i+1]].toarray(), axis=0)\n",
    "        tf.append(batch_result)\n",
    "        i += 1\n",
    "    term_freq_df = pd.DataFrame([np.sum(tf, axis=0)], columns=cvec.get_feature_names()).transpose()\n",
    "    \n",
    "    # Now organize everything into the dataframes\n",
    "    term_freq_df.columns = ['count']\n",
    "    term_freq_df.index.name = 'word'\n",
    "    sorted_term_freq_df = pd.DataFrame(term_freq_df.sort_values(by='count', ascending=False)['count'])\n",
    "    return sorted_term_freq_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b291a4-088e-463e-8a5e-326bcb0d9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count  proportion\n",
      "word                    \n",
      "the   186019    0.050628\n",
      "and   107893    0.029365\n",
      "to    103090    0.028058\n",
      "of     89417    0.024336\n",
      "a      81307    0.022129\n",
      "             count    proportion\n",
      "word                            \n",
      "interestel       1  2.721674e-07\n",
      "interethnic      1  2.721674e-07\n",
      "interfaced       1  2.721674e-07\n",
      "interfacing      1  2.721674e-07\n",
      "𐌼𐌿𐌽𐌳𐍃            1  2.721674e-07\n"
     ]
    }
   ],
   "source": [
    "term_df, df = count_vocab_frequencies(df)\n",
    "# p(word).  Note that multiple occurrences of a word in a sentence increases its probability.\n",
    "# We may want to do something about that.\n",
    "term_df['proportion'] = term_df['count']/float(sum(term_df['count']))\n",
    "# Sanity check\n",
    "print(term_df.head())\n",
    "print(term_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8202c12e-6d02-4dbc-a896-c1ce1d3b34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PMI(df_coo, subgroup):\n",
    "    # PMI(x;y) = h(y) - h(y|x)\n",
    "    #          = h(subgroup) - h(subgroup|word)\n",
    "    #          = log (p(subgroup|word) / p(subgroup))\n",
    "    # nPMI additionally divides by -log(p(x,y)) = -log(p(x|y)p(y))\n",
    "    #\n",
    "    # Calculation of p(subgroup)\n",
    "    subgroup_prob = term_df.loc[subgroup]['proportion']\n",
    "    # Apply a function to all words to calculate log p(subgroup|word)\n",
    "    # The word is indexed by mlb.classes_ ; \n",
    "    # we pull out the word using the mlb.classes_ index and then get its count using our main term_df\n",
    "    # Calculation:\n",
    "    # p(subgroup|word) = count(subgroup,word) / count(word)\n",
    "    #                  = x.values             / term_df.loc[mlb.classes_[x.index]]['count']\n",
    "    pmi_df = pd.DataFrame(df_coo.apply(lambda x: np.log(x.values/term_df.loc[mlb.classes_[x.index]]['count']/subgroup_prob)))\n",
    "    pmi_df.columns = ['pmi']\n",
    "    # If all went well, this will be correlated with high frequency words\n",
    "    # Until normalizing\n",
    "    # Note: A potentially faster solution for adding count, npmi, can be based on this:\n",
    "    # #df_test['size_kb'],  df_test['size_mb'], df_test['size_gb'] = zip(*df_test['size'].apply(sizes))\n",
    "    return pmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c6626f-ce6d-4630-a92b-ba89882743ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nPMI(pmi_df, df_coo):\n",
    "    normalize_df = pd.DataFrame(df_coo.apply(lambda x: -np.log(x.values/term_df.loc[mlb.classes_[x.index]]['count'] * term_df.loc[mlb.classes_[x.index]]['proportion'])))\n",
    "    # npmi_df = pmi_df/normalize_df\n",
    "    npmi_df = pd.DataFrame(pmi_df['pmi']/normalize_df[0])\n",
    "    npmi_df.columns = ['npmi']\n",
    "    return npmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f4ba76-c3ad-4f4e-bdba-8b2653ff8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(df_coo, subgroup):\n",
    "    # TBH I have no clue why this works.\n",
    "    count_df = pd.DataFrame(df_coo.apply(lambda x: pd.Series(x.values, mlb.classes_[x.index])))\n",
    "    count_df.columns=['count']\n",
    "    return count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7207c16-7f2c-470a-b9d7-6a52e03b6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating co-occurrences\n",
      "Getting counts for subgroup...\n",
      "            count\n",
      "0               3\n",
      "00              4\n",
      "000            27\n",
      "0000            0\n",
      "000002          0\n",
      "...           ...\n",
      "ﬁnancial        0\n",
      "ﬁrst            0\n",
      "ﬂexibility      0\n",
      "ﬂoors           0\n",
      "𐌼𐌿𐌽𐌳𐍃           0\n",
      "\n",
      "[100533 rows x 1 columns]\n",
      "Calculating PMI...\n",
      "                 pmi\n",
      "word                \n",
      "0           3.456918\n",
      "00          4.686165\n",
      "000         5.617594\n",
      "0000            -inf\n",
      "000002          -inf\n",
      "...              ...\n",
      "ﬁnancial        -inf\n",
      "ﬁrst            -inf\n",
      "ﬂexibility      -inf\n",
      "ﬂoors           -inf\n",
      "𐌼𐌿𐌽𐌳𐍃           -inf\n",
      "\n",
      "[100533 rows x 1 columns]\n",
      "Calculating nPMI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margaretmitchell/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/margaretmitchell/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                npmi\n",
      "word                \n",
      "0           0.246601\n",
      "00          0.341295\n",
      "000         0.475221\n",
      "0000             NaN\n",
      "000002           NaN\n",
      "...              ...\n",
      "ﬁnancial         NaN\n",
      "ﬁrst             NaN\n",
      "ﬂexibility       NaN\n",
      "ﬂoors            NaN\n",
      "𐌼𐌿𐌽𐌳𐍃            NaN\n",
      "\n",
      "[100533 rows x 1 columns]\n",
      "Calculating co-occurrences\n",
      "Getting counts for subgroup...\n",
      "            count\n",
      "0              22\n",
      "00              8\n",
      "000            59\n",
      "0000            0\n",
      "000002          0\n",
      "...           ...\n",
      "ﬁnancial        0\n",
      "ﬁrst            0\n",
      "ﬂexibility      0\n",
      "ﬂoors           0\n",
      "𐌼𐌿𐌽𐌳𐍃           0\n",
      "\n",
      "[100533 rows x 1 columns]\n",
      "Calculating PMI...\n",
      "                 pmi\n",
      "word                \n",
      "0           4.369043\n",
      "00          4.299007\n",
      "000         5.318989\n",
      "0000            -inf\n",
      "000002          -inf\n",
      "...              ...\n",
      "ﬁnancial        -inf\n",
      "ﬁrst            -inf\n",
      "ﬂexibility      -inf\n",
      "ﬂoors           -inf\n",
      "𐌼𐌿𐌽𐌳𐍃           -inf\n",
      "\n",
      "[100533 rows x 1 columns]\n",
      "Calculating nPMI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margaretmitchell/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                npmi\n",
      "word                \n",
      "0           0.363306\n",
      "00          0.329744\n",
      "000         0.481823\n",
      "0000             NaN\n",
      "000002           NaN\n",
      "...              ...\n",
      "ﬁnancial         NaN\n",
      "ﬁrst             NaN\n",
      "ﬂexibility       NaN\n",
      "ﬂoors            NaN\n",
      "𐌼𐌿𐌽𐌳𐍃            NaN\n",
      "\n",
      "[100533 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margaretmitchell/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Makes a sparse vector (shape: # sentences x # words),\n",
    "# with the count of each word per sentence.\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_mlb = pd.DataFrame(mlb.fit_transform(df['tokenized']))\n",
    "\n",
    "# Calculates PMI metrics\n",
    "paired_results = pd.DataFrame()\n",
    "results_dict = {}\n",
    "for subgroup in (subgroup1, subgroup2):\n",
    "    # Index of the subgroup word in the sparse vector\n",
    "    subgroup_idx = np.where(mlb.classes_ == subgroup)[0][0]\n",
    "    # Dataframe for the subgroup (with counts)\n",
    "    df_subgroup = df_mlb.iloc[:, subgroup_idx]\n",
    "    # Create cooccurence matrix for the given subgroup and all other words.\n",
    "    # Note it also includes the word itself, so that count should maybe be subtracted \n",
    "    # (the word will always co-occur with itself)\n",
    "    print('Calculating co-occurrences')\n",
    "    df_coo = pd.DataFrame(df_mlb.T.dot(df_subgroup))#.drop(index=subgroup_idx, axis=1)\n",
    "    print('Getting counts for subgroup...')\n",
    "    count_df = get_count(df_coo, subgroup)\n",
    "    print(count_df)\n",
    "    print('Calculating PMI...')\n",
    "    pmi_df = get_PMI(df_coo, subgroup)\n",
    "    print(pmi_df)\n",
    "    print('Calculating nPMI...')\n",
    "    #pmi_df_pair[subgroup] = pmi_df\n",
    "    npmi_df = get_nPMI(pmi_df, df_coo)\n",
    "    print(npmi_df)\n",
    "    #results_df = pd.concat([count_df,pmi_df,npmi_df], axis=1)\n",
    "    paired_results[subgroup + '-pmi']  = pmi_df['pmi']\n",
    "    paired_results[subgroup + '-npmi'] = npmi_df['npmi']\n",
    "    paired_results[subgroup + '-count'] = count_df['count'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0aea04d-09e6-4d0b-86c8-fed6fa26b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      woman-pmi  woman-npmi  woman-count   man-pmi  man-npmi  man-count\n",
      "word                                                                   \n",
      "0      3.456918    0.246601            3  4.369043  0.363306         22\n",
      "00     4.686165    0.341295            4  4.299007  0.329744          8\n",
      "000    5.617594    0.475221           27  5.318989  0.481823         59\n",
      "00am   6.725219    0.444882            1  5.644914  0.373419          1\n",
      "00pm   5.769707    0.381674            1  4.689402  0.310210          1\n",
      "...         ...         ...          ...       ...       ...        ...\n",
      "іn     7.641509    0.505496            1  6.561204  0.434033          1\n",
      "іt     7.353827    0.486466            1  6.273522  0.415002          1\n",
      "ү᧐u    9.433269    0.624024            1  8.352964  0.552560          1\n",
      "һow    9.433269    0.624024            1  8.352964  0.552560          1\n",
      "ꮇy     9.433269    0.624024            1  8.352964  0.552560          1\n",
      "\n",
      "[13826 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(paired_results.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d670174e-61b4-4af8-9203-540ec928dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# woman - man: If it's negative, it's man-biased; if it's positive, it's woman positive.\n",
    "npmi_bias = paired_results[subgroup1 + '-npmi'] - paired_results[subgroup2 + '-npmi'] #pd.DataFrame(results_dict[subgroup1]['npmi'] - results_dict[subgroup2]['npmi']).dropna()\n",
    "paired_results['npmi_bias'] = npmi_bias.dropna()\n",
    "paired_results = paired_results.dropna()\n",
    "#pmi_bias = pd.DataFrame(pmi_df_pair[subgroup1] - pmi_df_pair[subgroup2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63bedd3c-6ae4-44e5-a063-80d943efbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dd94085-e77e-4fe3-a955-1821f54426de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@20, the man bias is:\t0.39\n",
      "@20, the woman bias is:\t1.32\n"
     ]
    }
   ],
   "source": [
    "print(\"@%s, the %s bias is:\\t%.2f\" % (n, subgroup2, np.abs(sum(paired_results.npmi_bias[:n].values))))\n",
    "print(\"@%s, the %s bias is:\\t%.2f\" % (n, subgroup1, sum(paired_results.npmi_bias[-n:].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ec116a-29d5-4b88-8aac-cd3ced1aa8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most man-biased words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "man         -0.260967\n",
       "pure        -0.248211\n",
       "foot        -0.243202\n",
       "failed      -0.224456\n",
       "league      -0.211324\n",
       "decade      -0.205872\n",
       "minds       -0.204651\n",
       "squad       -0.204100\n",
       "leg         -0.199634\n",
       "precisely   -0.190910\n",
       "route       -0.190002\n",
       "gained      -0.189576\n",
       "origin      -0.186229\n",
       "desires     -0.183848\n",
       "premier     -0.183546\n",
       "blocked     -0.181568\n",
       "wave        -0.181540\n",
       "actor       -0.179628\n",
       "versions    -0.179389\n",
       "thinks      -0.178664\n",
       "Name: npmi_bias, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top %s most %s-biased words\" % (n, subgroup2))\n",
    "paired_results.npmi_bias.sort_values(ascending=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bcb965a-4709-4d03-b682-bc8c1af41175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most woman-biased words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "woman             0.296502\n",
       "quit              0.252845\n",
       "swedish           0.238161\n",
       "complement        0.233675\n",
       "vitamins          0.232567\n",
       "representation    0.229159\n",
       "miraculously      0.223465\n",
       "activism          0.219417\n",
       "coaster           0.219417\n",
       "shoots            0.215766\n",
       "childbirth        0.215424\n",
       "grooming          0.215424\n",
       "murray            0.212285\n",
       "strengthening     0.210629\n",
       "mai               0.209576\n",
       "alice             0.209439\n",
       "malaysia          0.206596\n",
       "workplace         0.205919\n",
       "flights           0.202572\n",
       "helpless          0.201522\n",
       "Name: npmi_bias, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top %s most %s-biased words\" % (n,subgroup1))\n",
    "paired_results.npmi_bias.sort_values(ascending=True)[-n:].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aef0f47-2990-4991-a26e-714421f63f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13826 entries, 0 to ꮇy\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   woman-pmi    13826 non-null  float64\n",
      " 1   woman-npmi   13826 non-null  float64\n",
      " 2   woman-count  13826 non-null  int64  \n",
      " 3   man-pmi      13826 non-null  float64\n",
      " 4   man-npmi     13826 non-null  float64\n",
      " 5   man-count    13826 non-null  int64  \n",
      " 6   npmi_bias    13826 non-null  float64\n",
      "dtypes: float64(5), int64(2)\n",
      "memory usage: 864.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(paired_results.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4803d76b-56a5-4b67-b8f4-8df204613d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      woman-pmi  woman-npmi  woman-count   man-pmi  man-npmi  man-count  \\\n",
      "word                                                                      \n",
      "0      3.456918    0.246601            3  4.369043  0.363306         22   \n",
      "00     4.686165    0.341295            4  4.299007  0.329744          8   \n",
      "000    5.617594    0.475221           27  5.318989  0.481823         59   \n",
      "00am   6.725219    0.444882            1  5.644914  0.373419          1   \n",
      "00pm   5.769707    0.381674            1  4.689402  0.310210          1   \n",
      "\n",
      "      npmi_bias  \n",
      "word             \n",
      "0     -0.116704  \n",
      "00     0.011551  \n",
      "000   -0.006601  \n",
      "00am   0.071464  \n",
      "00pm   0.071464  \n"
     ]
    }
   ],
   "source": [
    "print(paired_results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
