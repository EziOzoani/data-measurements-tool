{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97024cf4-c930-4aa1-a13f-ecdcc2462afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5404d6b6-6ce1-48df-8999-7da3fb082662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be defined by the drop down\n",
    "subgroup = \"woman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bf08cc-e18f-49fc-bae7-f03a9a492baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"c4\", \"en\", split= \"train\", streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca6ee78-6f96-45e2-8dad-ec745c953d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Just taking the first 5000 instances.\n"
     ]
    }
   ],
   "source": [
    "grab_n = 5000\n",
    "# For streaming data\n",
    "print('Note: Just taking the first %s instances.' % grab_n)\n",
    "data_head = data.take(grab_n)\n",
    "df = pd.DataFrame(data_head)\n",
    "# If not streaming, use:\n",
    "#df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d4d0c8-fc7c-4e99-8207-2e93d1c9b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vocab_frequencies(df):\n",
    "    \"\"\"\n",
    "    Based on an input pandas DataFrame with a 'text' column, \n",
    "    this function will count the occurrences of all words\n",
    "    with a frequency higher than 'cutoff' and will return another DataFrame\n",
    "    with the rows corresponding to the different vocabulary words\n",
    "    and the column to the count count of that word.\n",
    "    \"\"\"\n",
    "    # Move this up as a constant in larger code.\n",
    "    batch_size = 10\n",
    "    \n",
    "    # We do this to calculate per-word statistics\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    # Regex for pulling out single words\n",
    "    cvec = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\", lowercase=True)\n",
    "    \n",
    "    # We also do this because we need to have the tokenization per sentence \n",
    "    # so that we can look at co-occurrences of words across sentences for nPMI calculation\n",
    "    sent_tokenizer = cvec.build_tokenizer()\n",
    "    df['tokenized'] = df.text.apply(sent_tokenizer)\n",
    "    \n",
    "    # Fast calculation of single word counts\n",
    "    cvec.fit(df.text)\n",
    "    document_matrix = cvec.transform(df.text)\n",
    "    batches = np.linspace(0, df.shape[0], batch_size).astype(int)\n",
    "    i = 0\n",
    "    tf = []\n",
    "    while i < len(batches) - 1:\n",
    "        batch_result = np.sum(document_matrix[batches[i]:batches[i+1]].toarray(), axis=0)\n",
    "        tf.append(batch_result)\n",
    "        i += 1\n",
    "    term_freq_df = pd.DataFrame([np.sum(tf, axis=0)], columns=cvec.get_feature_names()).transpose()\n",
    "    \n",
    "    # Now organize everything into the dataframes\n",
    "    term_freq_df.columns = ['count']\n",
    "    term_freq_df.index.name = 'word'\n",
    "    sorted_term_freq_df = pd.DataFrame(term_freq_df.sort_values(by='count', ascending=False)['count'])\n",
    "    return sorted_term_freq_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b291a4-088e-463e-8a5e-326bcb0d9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      count  proportion\n",
      "word                   \n",
      "the   97414    0.051017\n",
      "and   55730    0.029186\n",
      "to    53855    0.028205\n",
      "of    46970    0.024599\n",
      "a     42078    0.022037\n",
      "               count    proportion\n",
      "word                              \n",
      "intraflora         1  5.237121e-07\n",
      "intramural         1  5.237121e-07\n",
      "intramurals        1  5.237121e-07\n",
      "intramuscular      1  5.237121e-07\n",
      "ï¬‚oors              1  5.237121e-07\n"
     ]
    }
   ],
   "source": [
    "term_df, df = count_vocab_frequencies(df)\n",
    "# p(word).  Note that multiple occurrences of a word in a sentence increases its probability.\n",
    "term_df['proportion'] = term_df['count']/float(sum(term_df['count']))\n",
    "# Sanity check\n",
    "print(term_df.head())\n",
    "print(term_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7207c16-7f2c-470a-b9d7-6a52e03b6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Makes a sparse vector (shape: # sentences x # words),\n",
    "# with the count of each word per sentence.\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_mlb = pd.DataFrame(mlb.fit_transform(df['tokenized']))\n",
    "# Index of the subgroup word in the sparse vector\n",
    "subgroup_idx = np.where(mlb.classes_ == subgroup)[0][0]\n",
    "# Dataframe for the subgroup (with counts)\n",
    "df_subgroup = df_mlb.iloc[:, subgroup_idx]\n",
    "# Create cooccurence matrix for the given subgroup and all other words.\n",
    "# Note it also includes the word itself, so that count should be subtracted \n",
    "# (the word will always co-occur with itself)\n",
    "df_coo = pd.DataFrame(df_mlb.T.dot(df_subgroup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8202c12e-6d02-4dbc-a896-c1ce1d3b34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMI(x;y) = h(y) - h(y|x)\n",
    "#          = h(subgroup) - h(subgroup|word)\n",
    "#          = log p(subgroup|word) - log p(subgroup))\n",
    "\n",
    "# log p(subgroup)\n",
    "subgroup_prob = np.log(term_df.loc[subgroup]['proportion'])\n",
    "# Apply a function to all words to calculate log p(subgroup|word)\n",
    "# The word is indexed by mlb.classes_ ; \n",
    "# we pull out the word using the index and then get its count using our main term_df\n",
    "# x[1] is the count of the word, given the subgroup\n",
    "pmi_df = pd.DataFrame(df_coo.apply(lambda x: np.log(x[1]/term_df.loc[mlb.classes_[x.index]]['count']) - subgroup_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21b8405-9d94-4394-8b24-18346366504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "word           \n",
      "the   -1.368207\n",
      "and   -0.809756\n",
      "to    -0.775532\n",
      "of    -0.638746\n",
      "a     -0.528762\n",
      "in    -0.305339\n",
      "is     0.078404\n",
      "for    0.141734\n",
      "you    0.271072\n",
      "that   0.312754\n",
      "it     0.428533\n",
      "with   0.452654\n",
      "i      0.466381\n",
      "on     0.578802\n",
      "s      0.703117\n",
      "are    0.735654\n",
      "as     0.764770\n",
      "this   0.797710\n",
      "be     0.807518\n",
      "your   0.903788\n",
      "we     0.977421\n",
      "or     0.993300\n",
      "have   1.046176\n",
      "at     1.052741\n",
      "from   1.082889\n",
      "can    1.146943\n",
      "by     1.157152\n",
      "was    1.162812\n",
      "will   1.177365\n",
      "not    1.317952\n",
      "an     1.329010\n",
      "all    1.430064\n",
      "but    1.446546\n",
      "they   1.498949\n",
      "our    1.527146\n",
      "if     1.535350\n",
      "has    1.544000\n",
      "their  1.640482\n",
      "more   1.656415\n",
      "my     1.668962\n",
      "so     1.676049\n",
      "one    1.692344\n",
      "t      1.698938\n",
      "which  1.811306\n",
      "about  1.835530\n",
      "there  1.850043\n",
      "also   1.870251\n",
      "what   1.871298\n",
      "when   1.874184\n",
      "up     1.875236\n"
     ]
    }
   ],
   "source": [
    "# If all went well, this will be correlated with high/low frequency words\n",
    "# Until normalizing\n",
    "print(pmi_df.sort_values(by=[0])[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
